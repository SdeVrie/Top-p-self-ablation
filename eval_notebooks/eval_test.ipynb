{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wandb Test\n",
    "\n",
    "Demonstrates how to use some utils for integrating tests with wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os, sys\n",
    "\n",
    "# Add the directory containing the utils folder to the system path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "import dotenv\n",
    "from utils.testing import access_wandb_runs, update_run, download_models\n",
    "\n",
    "# We must get the api key from the .env\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fanciful-fog-78\n",
      "earnest-moon-79\n",
      "super-violet-80\n",
      "cosmic-leaf-81\n",
      "upbeat-glitter-83\n",
      "comfy-cherry-84\n",
      "cosmic-leaf-81-part2\n",
      "major-planet-86\n",
      "major-planet-86-part2\n",
      "major-planet-86-part3\n",
      "light-morning-92\n",
      "deft-dew-98\n"
     ]
    }
   ],
   "source": [
    "runs = access_wandb_runs(\"j-l-ferrao-university-of-groningen\", \"gpt-neo-self-ablation\")\n",
    "\n",
    "for run in runs:\n",
    "    print(run.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded best_model_20241105.pt to ../model_weights/fanciful-fog-78\n",
      "Downloaded best_model_20241106.pt to ../model_weights/earnest-moon-79\n",
      "Downloaded best_model_20241105.pt to ../model_weights/super-violet-80\n",
      "Downloaded best_model_20241108.pt to ../model_weights/cosmic-leaf-81\n",
      "Downloaded best_model_20241109.pt to ../model_weights/upbeat-glitter-83\n",
      "Downloaded best_model_20241109.pt to ../model_weights/comfy-cherry-84\n",
      "Downloaded best_model_20241111.pt to ../model_weights/cosmic-leaf-81-part2\n",
      "Downloaded best_model_20241113.pt to ../model_weights/major-planet-86\n",
      "Downloaded best_model_20241113.pt to ../model_weights/major-planet-86-part2\n",
      "Downloaded best_model_20241114.pt to ../model_weights/major-planet-86-part3\n",
      "Downloaded best_model_20241116.pt to ../model_weights/light-morning-92\n",
      "Downloaded best_model_20241119.pt to ../model_weights/deft-dew-98\n"
     ]
    }
   ],
   "source": [
    "download_models(runs, \"../model_weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code will update the stats stored online in wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run = runs[0]\n",
    "\n",
    "test_results = {\n",
    "    'test_var': 42\n",
    "}\n",
    "\n",
    "update_run(first_run, test_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAE Lens test\n",
    "\n",
    "Testing how the SAE lens library works. Following tutorials from [here](https://jbloomaus.github.io/SAELens/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sae_lens import SAE\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jazhyc/miniconda3/envs/ablation/lib/python3.11/site-packages/sae_lens/sae.py:145: UserWarning: \n",
      "This SAE has non-empty model_from_pretrained_kwargs. \n",
      "For optimal performance, load the model like so:\n",
      "model = HookedSAETransformer.from_pretrained_no_processing(..., **cfg.model_from_pretrained_kwargs)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # String needs to be passed\n",
    "\n",
    "# \n",
    "sae, cfg_dict, sparsity = SAE.from_pretrained(\n",
    "    release = \"gpt2-small-res-jb\", # see other options in sae_lens/pretrained_saes.yaml\n",
    "    sae_id = \"blocks.8.hook_resid_pre\", # won't always be a hook point\n",
    "    device = device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAE(\n",
       "  (activation_fn): ReLU()\n",
       "  (hook_sae_input): HookPoint()\n",
       "  (hook_sae_acts_pre): HookPoint()\n",
       "  (hook_sae_acts_post): HookPoint()\n",
       "  (hook_sae_output): HookPoint()\n",
       "  (hook_sae_recons): HookPoint()\n",
       "  (hook_sae_error): HookPoint()\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_name': 'gpt2-small',\n",
       " 'hook_point': 'blocks.8.hook_resid_pre',\n",
       " 'hook_point_layer': 8,\n",
       " 'hook_point_head_index': None,\n",
       " 'dataset_path': 'Skylion007/openwebtext',\n",
       " 'is_dataset_tokenized': False,\n",
       " 'context_size': 128,\n",
       " 'use_cached_activations': False,\n",
       " 'cached_activations_path': 'activations/Skylion007_openwebtext/gpt2-small/blocks.8.hook_resid_pre',\n",
       " 'd_in': 768,\n",
       " 'n_batches_in_buffer': 128,\n",
       " 'total_training_tokens': 300000000,\n",
       " 'store_batch_size': 32,\n",
       " 'device': 'cuda',\n",
       " 'seed': 42,\n",
       " 'dtype': 'torch.float32',\n",
       " 'b_dec_init_method': 'geometric_median',\n",
       " 'expansion_factor': 32,\n",
       " 'from_pretrained_path': None,\n",
       " 'l1_coefficient': 8e-05,\n",
       " 'lr': 0.0004,\n",
       " 'lr_scheduler_name': None,\n",
       " 'lr_warm_up_steps': 5000,\n",
       " 'train_batch_size': 4096,\n",
       " 'use_ghost_grads': False,\n",
       " 'feature_sampling_window': 1000,\n",
       " 'feature_sampling_method': None,\n",
       " 'resample_batches': 1028,\n",
       " 'feature_reinit_scale': 0.2,\n",
       " 'dead_feature_window': 5000,\n",
       " 'dead_feature_estimation_method': 'no_fire',\n",
       " 'dead_feature_threshold': 1e-08,\n",
       " 'log_to_wandb': True,\n",
       " 'wandb_project': 'mats_sae_training_gpt2_small_resid_pre_5',\n",
       " 'wandb_entity': None,\n",
       " 'wandb_log_frequency': 100,\n",
       " 'n_checkpoints': 10,\n",
       " 'checkpoint_path': 'checkpoints/ut7lhl4q',\n",
       " 'd_sae': 24576,\n",
       " 'tokens_per_buffer': 67108864,\n",
       " 'run_name': '24576-L1-8e-05-LR-0.0004-Tokens-3.000e+08',\n",
       " 'model_from_pretrained_kwargs': {'center_writing_weights': True},\n",
       " 'neuronpedia_id': 'gpt2-small/8-res-jb',\n",
       " 'prepend_bos': True,\n",
       " 'dataset_trust_remote_code': True,\n",
       " 'apply_b_dec_to_input': True,\n",
       " 'finetuning_scaling_factor': False,\n",
       " 'sae_lens_training_version': None,\n",
       " 'activation_fn_str': 'relu',\n",
       " 'architecture': 'standard',\n",
       " 'normalize_activations': 'none'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.8268, -3.0495, -2.9602,  ..., -2.5930, -3.1867, -2.5810],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ablation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
